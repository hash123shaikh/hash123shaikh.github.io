---
layout: none
permalink: /portfolio/
---
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Research Projects - Hasan Shaikh</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800&display=swap" rel="stylesheet">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        html {
            scroll-behavior: smooth;
        }

        body {
            font-family: 'Inter', sans-serif;
            background: #0a0e17;
            color: #e4e6eb;
            overflow-x: hidden;
        }

        /* Navigation */
        .navbar {
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            z-index: 1000;
            background: rgba(10, 14, 23, 0.95);
            backdrop-filter: blur(20px);
            border-bottom: 1px solid rgba(255, 255, 255, 0.1);
            padding: 1rem 0;
        }

        .navbar-content {
            max-width: 1600px;
            margin: 0 auto;
            padding: 0 3rem;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        .navbar-brand {
            display: flex;
            flex-direction: column;
        }

        .navbar-name {
            font-size: 1.3rem;
            font-weight: 700;
            color: #fff;
            text-decoration: none;
        }

        .navbar-tagline {
            font-size: 0.85rem;
            color: #00d4ff;
        }

        .navbar-links {
            display: flex;
            gap: 2rem;
        }

        .navbar-links a {
            color: #e4e6eb;
            text-decoration: none;
            font-weight: 500;
            transition: color 0.3s ease;
        }

        .navbar-links a:hover,
        .navbar-links a.active {
            color: #00d4ff;
        }

        /* Animated gradient background */
        .bg-gradient {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            z-index: 0;
            background: linear-gradient(135deg, #0a0e17 0%, #1a1f35 50%, #0a0e17 100%);
            animation: gradientShift 15s ease infinite;
        }

        @keyframes gradientShift {
            0%, 100% { background-position: 0% 50%; }
            50% { background-position: 100% 50%; }
        }

        /* Particle canvas */
        #particles {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            z-index: 1;
        }

        /* Main content */
        .content {
            position: relative;
            z-index: 10;
            max-width: 1400px;
            margin: 0 auto;
            padding: 8rem 3rem 4rem 3rem;
        }

        /* Header */
        .page-header {
            text-align: center;
            margin-bottom: 4rem;
        }

        .page-title {
            font-size: 3.5rem;
            font-weight: 800;
            margin-bottom: 1rem;
            background: linear-gradient(135deg, #00d4ff 0%, #b794f6 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }

        .page-subtitle {
            font-size: 1.2rem;
            color: #b8bcc8;
        }

        /* Project Section */
        .project-section {
            margin-bottom: 3rem;
        }

        .section-header {
            display: flex;
            align-items: center;
            gap: 1rem;
            margin-bottom: 2rem;
        }

        .section-icon {
            font-size: 2rem;
        }

        .section-title {
            font-size: 2rem;
            font-weight: 700;
            color: #fff;
        }

        /* Project Card */
        .project-card {
            background: rgba(255, 255, 255, 0.03);
            backdrop-filter: blur(20px);
            border: 1px solid rgba(255, 255, 255, 0.1);
            border-radius: 24px;
            padding: 2.5rem;
            margin-bottom: 2rem;
            transition: all 0.3s ease;
            position: relative;
            overflow: hidden;
        }

        .project-card::before {
            content: '';
            position: absolute;
            top: 0;
            left: -100%;
            width: 100%;
            height: 100%;
            background: linear-gradient(90deg, transparent, rgba(0, 212, 255, 0.1), transparent);
            transition: left 0.6s ease;
        }

        .project-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 12px 48px rgba(0, 212, 255, 0.2);
            border-color: rgba(0, 212, 255, 0.3);
        }

        .project-card:hover::before {
            left: 100%;
        }

        .project-card.featured {
            border-left: 4px solid #00d4ff;
            background: rgba(0, 212, 255, 0.05);
        }

        .project-header {
            display: flex;
            justify-content: space-between;
            align-items: flex-start;
            margin-bottom: 1.5rem;
            gap: 1rem;
        }

        .project-title {
            font-size: 1.6rem;
            font-weight: 700;
            color: #00d4ff;
            margin-bottom: 0.5rem;
            line-height: 1.4;
        }

        .project-org {
            font-size: 0.95rem;
            color: #b8bcc8;
            font-weight: 500;
        }

        .project-period {
            flex-shrink: 0;
            padding: 0.5rem 1rem;
            background: rgba(0, 212, 255, 0.1);
            border: 1px solid rgba(0, 212, 255, 0.3);
            border-radius: 20px;
            font-size: 0.85rem;
            color: #00d4ff;
            font-weight: 600;
        }

        .project-description {
            font-size: 1.05rem;
            color: #e4e6eb;
            line-height: 1.8;
            margin-bottom: 1.5rem;
        }

        /* Key Contributions */
        .contributions-title {
            font-size: 1.1rem;
            font-weight: 700;
            color: #fff;
            margin-bottom: 1rem;
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }

        .contributions-list {
            list-style: none;
            margin-bottom: 1.5rem;
        }

        .contributions-list li {
            position: relative;
            padding-left: 2rem;
            margin-bottom: 0.8rem;
            color: #b8bcc8;
            line-height: 1.7;
        }

        .contributions-list li::before {
            content: '‚ñ∏';
            position: absolute;
            left: 0.5rem;
            color: #00d4ff;
            font-weight: 700;
        }

        .contributions-list strong {
            color: #fff;
            font-weight: 600;
        }

        .metric {
            color: #f3a03d;
            font-weight: 700;
        }

        /* Technologies */
        .tech-section {
            margin-top: 1.5rem;
            padding-top: 1.5rem;
            border-top: 1px solid rgba(255, 255, 255, 0.1);
        }

        .tech-label {
            font-size: 0.9rem;
            color: #6b7280;
            font-weight: 600;
            margin-bottom: 0.8rem;
        }

        .tech-tags {
            display: flex;
            flex-wrap: wrap;
            gap: 0.6rem;
        }

        .tech-tag {
            padding: 0.4rem 0.9rem;
            background: rgba(0, 212, 255, 0.1);
            border: 1px solid rgba(0, 212, 255, 0.3);
            border-radius: 20px;
            font-size: 0.85rem;
            color: #00d4ff;
            font-weight: 500;
        }

        /* Links */
        .project-links {
            display: flex;
            gap: 1rem;
            flex-wrap: wrap;
            margin-top: 1.5rem;
        }

        .project-link {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.7rem 1.5rem;
            background: rgba(0, 212, 255, 0.1);
            border: 1px solid rgba(0, 212, 255, 0.3);
            border-radius: 10px;
            color: #00d4ff;
            text-decoration: none;
            font-weight: 600;
            font-size: 0.9rem;
            transition: all 0.3s ease;
        }

        .project-link:hover {
            background: rgba(0, 212, 255, 0.2);
            transform: translateY(-2px);
        }

        /* Stats Grid */
        .stats-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 1rem;
            margin: 1.5rem 0;
        }

        .stat-box {
            background: rgba(0, 212, 255, 0.05);
            border: 1px solid rgba(0, 212, 255, 0.2);
            border-radius: 12px;
            padding: 1rem;
            text-align: center;
        }

        .stat-value {
            font-size: 2rem;
            font-weight: 800;
            color: #00d4ff;
            margin-bottom: 0.3rem;
        }

        .stat-label {
            font-size: 0.85rem;
            color: #b8bcc8;
        }

        /* Footer */
        .footer {
            position: relative;
            z-index: 10;
            background: rgba(10, 14, 23, 0.95);
            border-top: 1px solid rgba(255, 255, 255, 0.1);
            padding: 3rem 0 1.5rem 0;
            margin-top: 4rem;
        }

        .footer-content-wrapper {
            max-width: 1400px;
            margin: 0 auto;
            padding: 0 3rem;
            display: flex;
            justify-content: space-between;
            gap: 4rem;
        }

        .footer-left {
            flex: 1;
        }

        .footer-name {
            font-size: 1.5rem;
            font-weight: 700;
            color: #fff;
            margin-bottom: 1rem;
        }

        .footer-bio {
            font-size: 1rem;
            color: #b8bcc8;
            line-height: 1.6;
            margin-bottom: 1.5rem;
        }

        .footer-quote {
            background: rgba(0, 212, 255, 0.05);
            border-left: 3px solid #00d4ff;
            padding: 1rem 1.5rem;
            border-radius: 8px;
        }

        .quote-text {
            font-size: 0.95rem;
            color: #b8bcc8;
            font-style: italic;
            margin-bottom: 0.5rem;
        }

        .quote-author {
            font-size: 0.85rem;
            color: #00d4ff;
            text-align: right;
        }

        .footer-right {
            flex: 0 0 300px;
        }

        .connect-title {
            font-size: 1.3rem;
            font-weight: 700;
            color: #fff;
            margin-bottom: 1.5rem;
        }

        .social-links {
            display: flex;
            flex-direction: column;
            gap: 1rem;
        }

        .social-link {
            display: flex;
            align-items: center;
            gap: 1rem;
            padding: 0.8rem 1.2rem;
            background: rgba(255, 255, 255, 0.03);
            border: 1px solid rgba(255, 255, 255, 0.1);
            border-radius: 10px;
            color: #b8bcc8;
            text-decoration: none;
            font-weight: 500;
            transition: all 0.3s ease;
        }

        .social-link:hover {
            background: rgba(0, 212, 255, 0.1);
            border-color: rgba(0, 212, 255, 0.3);
            color: #00d4ff;
            transform: translateX(5px);
        }

        .social-icon {
            font-size: 1.3rem;
        }

        .footer-bottom {
            max-width: 1400px;
            margin: 0 auto;
            padding: 2rem 3rem 0 3rem;
            border-top: 1px solid rgba(255, 255, 255, 0.05);
            margin-top: 2rem;
        }

        .copyright {
            text-align: center;
            font-size: 0.9rem;
            color: #6b7280;
        }

        /* Responsive */
        @media (max-width: 768px) {
            .content {
                padding: 7rem 1rem 3rem 1rem;
            }

            .navbar-content {
                padding: 0 1rem;
                flex-direction: column;
                gap: 1rem;
            }

            .navbar-links {
                gap: 1rem;
                flex-wrap: wrap;
                justify-content: center;
            }

            .page-title {
                font-size: 2.5rem;
            }

            .project-header {
                flex-direction: column;
            }

            .project-links {
                flex-direction: column;
            }

            .project-link {
                width: 100%;
                justify-content: center;
            }

            .footer-content-wrapper {
                flex-direction: column;
                gap: 3rem;
                padding: 0 1rem;
            }

            .footer-left {
                text-align: center;
            }

            .footer-bottom {
                padding: 2rem 1rem 0 1rem;
            }
        }
    </style>
</head>
<body>
    <!-- Navigation -->
    <nav class="navbar">
        <div class="navbar-content">
            <a href="/" style="text-decoration: none;">
                <div class="navbar-brand">
                    <div class="navbar-name">Hasan Shaikh</div>
                    <div class="navbar-tagline">Researcher in AI for Cancer Imaging</div>
                </div>
            </a>
            <div class="navbar-links">
                <a href="/">Home</a>
                <a href="/portfolio/" class="active">Projects</a>
                <a href="/publications/">Publications</a>
                <a href="/cv/">CV</a>
                <a href="/contact/">Contact</a>
            </div>
        </div>
    </nav>

    <div class="bg-gradient"></div>
    <canvas id="particles"></canvas>

    <div class="content">
        <!-- Header -->
        <div class="page-header">
            <h1 class="page-title">Research Projects</h1>
            <p class="page-subtitle">Building intelligent systems that transform cancer care through AI and medical imaging</p>
        </div>

        <!-- QIRAIL Projects -->
        <section class="project-section">
            <div class="section-header">
                <span class="section-icon">üè•</span>
                <h2 class="section-title">QIRAIL, CMC Vellore</h2>
            </div>

            <!-- Project 1: Radiomics Risk Stratification -->
            <div class="project-card featured">
                <div class="project-header">
                    <div>
                        <h3 class="project-title">Radiomics-Based Risk Stratification in Head & Neck Cancer</h3>
                        <p class="project-org">DBT/Wellcome Trust India Alliance Funded Project | QIRAIL, CMC Vellore</p>
                    </div>
                    <span class="project-period">Aug 2024 - Present</span>
                </div>

                <p class="project-description">
                    <strong>Background:</strong> Accurately estimating individual cancer patient risk of early disease failure is crucial for understanding tumor biology, stratifying patients, and tailoring personalized treatment strategies. Current risk stratification methods inadequately predict locoregional recurrence in head and neck cancer patients, creating a critical need for improved prediction models.
                </p>

                <p class="project-description">
                    <strong>The Challenge:</strong> Cancer radiomics converts routine radiological images‚Äîtraditionally interpreted qualitatively‚Äîinto quantifiable data describing tumor phenotypes. Unlike tissue biopsies, radiomics captures information from the entire tumor non-invasively, reducing sampling errors and requiring no additional radiation exposure for patients.
                </p>

                <p class="project-description">
                    <strong>Our Approach:</strong> We systematically compared 8 metaheuristic feature selection algorithms (Particle Swarm Optimization, Genetic Algorithms, Grey Wolf Optimizer, Whale Optimization Algorithm, etc.) combined with 7 machine learning classifiers on pretreatment CT scans from 367 patients. The key research question: <em>Can pre-treatment radiomics signatures accurately identify advanced HNC patients at higher risk of recurrence?</em>
                </p>

                <div class="stats-grid">
                    <div class="stat-box">
                        <div class="stat-value">367</div>
                        <div class="stat-label">Patients Analyzed</div>
                    </div>
                    <div class="stat-box">
                        <div class="stat-value">0.81</div>
                        <div class="stat-label">AUC (95% CI: 0.62-0.95)</div>
                    </div>
                    <div class="stat-box">
                        <div class="stat-value">10</div>
                        <div class="stat-label">Feature Signature</div>
                    </div>
                    <div class="stat-box">
                        <div class="stat-value">56</div>
                        <div class="stat-label">Model Combinations</div>
                    </div>
                </div>

                <h4 class="contributions-title">üéØ Key Achievements</h4>
                <ul class="contributions-list">
                    <li><strong>Developed interpretable prediction model:</strong> Created a clinically meaningful 10-feature signature (4 clinical + 6 radiomics features) that achieved <span class="metric">AUC 0.81 (95% CI: 0.62-0.95)</span> on held-out test set while maintaining interpretability for clinical adoption</li>
                    <li><strong>Systematic metaheuristic comparison:</strong> First comprehensive evaluation of 8 metaheuristic optimizers (PSO, GA, GWO, WOA, etc.) across multiple classifiers (Logistic Regression, Naive Bayes, SVM, Random Forest, etc.) specifically for radiomics feature selection in HNC</li>
                    <li><strong>Mechanistic insights into model behavior:</strong> Discovered and documented why larger feature sets underperformed due to overfitting in high-dimensional radiomics data, providing valuable guidance for future model development</li>
                    <li><strong>Clinical validation framework:</strong> Established collaboration with oncology team to validate biological plausibility of selected radiomic features, ensuring features reflect real tumor biology rather than imaging artifacts</li>
                    <li><strong>Reproducible pipeline:</strong> Built end-to-end analysis pipeline from DICOM retrieval through feature extraction to model validation, enabling future multi-institutional validation studies</li>
                </ul>

                <h4 class="contributions-title">üî¨ Methodology Details</h4>
                <ul class="contributions-list">
                    <li><strong>Feature extraction:</strong> Extracted comprehensive radiomic features from pretreatment CT scans using PyRadiomics, including first-order statistics, shape features, and texture features (GLCM, GLRLM, GLSZM)</li>
                    <li><strong>Feature selection strategies:</strong> Implemented and compared LASSO regularization, SelectKBest univariate selection, and nature-inspired metaheuristics (PSO, WOA) for optimal feature subset identification</li>
                    <li><strong>Model validation:</strong> Employed rigorous temporal splitting and nested cross-validation to prevent data leakage and ensure unbiased performance estimates</li>
                    <li><strong>Performance metrics:</strong> Evaluated models using ROC AUC, calibration curves, decision curve analysis, and clinical net benefit to assess both discrimination and clinical utility</li>
                </ul>

                <div class="tech-section">
                    <div class="tech-label">Technologies & Tools</div>
                    <div class="tech-tags">
                        <span class="tech-tag">Python</span>
                        <span class="tech-tag">PyRadiomics</span>
                        <span class="tech-tag">scikit-learn</span>
                        <span class="tech-tag">XGBoost</span>
                        <span class="tech-tag">PSO</span>
                        <span class="tech-tag">Genetic Algorithms</span>
                        <span class="tech-tag">Grey Wolf Optimizer</span>
                        <span class="tech-tag">SHAP</span>
                        <span class="tech-tag">Orthanc DICOM</span>
                    </div>
                </div>
            </div>

            <!-- Project 2: Reproducibility Study -->
            <div class="project-card">
                <div class="project-header">
                    <div>
                        <h3 class="project-title">Reproducibility Study: CNN-Based Head and Neck Cancer Prognosis</h3>
                        <p class="project-org">QIRAIL, CMC Vellore</p>
                    </div>
                    <span class="project-period">2024</span>
                </div>

                <p class="project-description">
                    Critical examination of reproducibility claims in published CNN model for head and neck cancer outcomes, revealing significant dataset and documentation issues while successfully reproducing results.
                </p>

                <h4 class="contributions-title">üéØ Key Contributions</h4>
                <ul class="contributions-list">
                    <li><strong>Challenged reproducibility claims</strong> of published CNN model by attempting complete replication across three HNC outcomes (distant metastasis, locoregional failure, overall survival)</li>
                    <li><strong>Identified major dataset and documentation issues:</strong> Incorrectly provided datasets, multiple errors in data files, inadequate result reporting protocols, and poor documentation that contradicted reproducibility claims</li>
                    <li><strong>Successfully reproduced results</strong> despite paper's flaws by correcting dataset errors, implementing missing preprocessing steps, and establishing proper validation protocols</li>
                    <li><strong>Authors acknowledged reproducibility failures:</strong> Communicated findings that led to author recognition of dataset errors and documentation inadequacies in their published work</li>
                </ul>

                <div class="tech-section">
                    <div class="tech-label">Technologies & Tools</div>
                    <div class="tech-tags">
                        <span class="tech-tag">Python</span>
                        <span class="tech-tag">PyTorch</span>
                        <span class="tech-tag">CNN</span>
                        <span class="tech-tag">DICOM</span>
                        <span class="tech-tag">Data Validation</span>
                    </div>
                </div>

                <div class="project-links">
                    <a href="https://github.com/hash123shaikh/Reproducibility-of-HNC_CNN.git" target="_blank" class="project-link">
                        üîó GitHub Repository
                    </a>
                </div>
            </div>

            <!-- Project 3: CHAVI Biobank -->
            <div class="project-card">
                <div class="project-header">
                    <div>
                        <h3 class="project-title">CHAVI: CompreHensive Digital ArchiVe of Cancer Imaging</h3>
                        <p class="project-org">India's First National Oncology Imaging Biobank | Led by Tata Memorial Centre & IIT Kharagpur</p>
                    </div>
                    <span class="project-period">2024</span>
                </div>

                <p class="project-description">
                    <strong>The National Challenge:</strong> Development of AI and machine learning models in oncology requires access to large-scale, high-quality, and standardized imaging datasets. However, region-specific imaging biobanks remain scarce in South Asia, limiting AI research capabilities and model generalizability to diverse patient populations.
                </p>

                <p class="project-description">
                    <strong>CHAVI's Mission:</strong> Creating India's first centralized repository of de-identified oncology imaging data to democratize medical data for research, foster reproducibility and collaboration, and enable AI-driven innovations in early cancer detection, prognosis prediction, and personalized treatment strategies.
                </p>

                <p class="project-description">
                    <strong>Our Contribution:</strong> Designed and implemented comprehensive data preparation and integration pipeline for seamless upload of Head and Neck Cancer imaging and clinical data to CHAVI, ensuring ethical compliance with HIPAA and GDPR while maintaining data utility for AI research.
                </p>

                <div class="stats-grid">
                    <div class="stat-box">
                        <div class="stat-value">304+</div>
                        <div class="stat-label">HNC Cases Curated</div>
                    </div>
                    <div class="stat-box">
                        <div class="stat-value">100%</div>
                        <div class="stat-label">FAIR Compliant</div>
                    </div>
                    <div class="stat-box">
                        <div class="stat-value">Zero</div>
                        <div class="stat-label">Privacy Violations</div>
                    </div>
                    <div class="stat-box">
                        <div class="stat-value">Multi</div>
                        <div class="stat-label">Institutional</div>
                    </div>
                </div>

                <h4 class="contributions-title">üéØ Key Achievements</h4>
                <ul class="contributions-list">
                    <li><strong>Curated 304+ anonymized HNC cases</strong> with comprehensive validated clinical and imaging metadata, establishing CMC Vellore as a major contributor to India's national cancer imaging repository</li>
                    <li><strong>Automated FAIR-compliant pipeline:</strong> Built end-to-end data processing system ensuring datasets are Findable, Accessible, Interoperable, and Reusable for multi-institutional research collaboration</li>
                    <li><strong>Rigorous de-identification protocols:</strong> Implemented comprehensive PHI/PII removal from both DICOM headers and clinical reports while maintaining data linkage integrity through anonymized identifiers</li>
                    <li><strong>Quality control framework:</strong> Established systematic validation protocols detecting formatting errors, completing missing fields through logical inference, and standardizing data formats across institutional sources</li>
                    <li><strong>Ethical compliance documentation:</strong> Maintained complete audit trails ensuring adherence to HIPAA and GDPR throughout data handling lifecycle</li>
                </ul>

                <h4 class="contributions-title">üî¨ Technical Implementation</h4>
                <ul class="contributions-list">
                    <li><strong>Data preprocessing pipeline:</strong> Automated detection and correction of formatting errors, completion of missing fields, and standardization according to CHAVI's structured requirements</li>
                    <li><strong>De-identification workflow:</strong> Multi-stage process removing patient names, hospital identifiers, and PII from imaging metadata (DICOM headers) and masking free-text fields in clinical reports</li>
                    <li><strong>Data harmonization:</strong> Mapped clinical data into standardized formats ensuring interoperability across research platforms, with consistent imaging parameters and metadata fields</li>
                    <li><strong>Anonymized linking:</strong> Assigned unique non-identifiable keys enabling multimodal research (combining clinical, imaging, and outcome data) without compromising patient privacy</li>
                    <li><strong>AI-readiness optimization:</strong> Structured datasets specifically for machine learning applications, ensuring compatibility with common deep learning frameworks</li>
                </ul>

                <h4 class="contributions-title">üåê Broader Impact</h4>
                <ul class="contributions-list">
                    <li><strong>Democratizing oncology research:</strong> Contributing to public repository enables researchers nationwide to access curated datasets without institutional barriers</li>
                    <li><strong>Addressing regional disparities:</strong> CHAVI fills critical gap in South Asian imaging biobanks, enabling development of AI models trained on locally relevant patient populations</li>
                    <li><strong>Fostering collaboration:</strong> Standardized data formats facilitate multi-institutional validation studies and reproducible research across cancer centers</li>
                    <li><strong>Enabling precision oncology:</strong> Large-scale datasets support development of personalized treatment strategies based on imaging biomarkers</li>
                </ul>

                <div class="tech-section">
                    <div class="tech-label">Technologies & Tools</div>
                    <div class="tech-tags">
                        <span class="tech-tag">Python</span>
                        <span class="tech-tag">DICOM Processing</span>
                        <span class="tech-tag">Orthanc</span>
                        <span class="tech-tag">XNAT</span>
                        <span class="tech-tag">FAIR Principles</span>
                        <span class="tech-tag">HIPAA/GDPR</span>
                        <span class="tech-tag">Data Anonymization</span>
                        <span class="tech-tag">ETL Pipeline</span>
                    </div>
                </div>
            </div>

            <!-- Project 4: Automated Segmentation -->
            <div class="project-card">
                <div class="project-header">
                    <div>
                        <h3 class="project-title">CT-only Automated Segmentation Using 3D nnU-Net</h3>
                        <p class="project-org">Collaboration with NIT Surathkal | Submitted to Journal of Imaging Informatics in Medicine</p>
                    </div>
                    <span class="project-period">2024</span>
                </div>

                <p class="project-description">
                    <strong>Clinical Problem:</strong> Head and neck cancer requires precise tumor delineation for effective radiotherapy planning. Manual segmentation is time-consuming (30-60 minutes per case) and subject to significant inter-observer variability. Existing automated methods rely on multimodal PET/CT imaging, which is costly ($1000+ per scan), less accessible in resource-limited settings, and burdensome for patients.
                </p>

                <p class="project-description">
                    <strong>Our Innovation:</strong> We developed a <em>CT-only</em> automated segmentation framework using 3D nnU-Net that eliminates the need for expensive PET scans while maintaining clinical-grade accuracy. This approach offers a robust, cost-effective, and scalable solution that can democratize access to precision radiotherapy planning.
                </p>

                <p class="project-description">
                    <strong>Why CT-only Matters:</strong> CT scanners are 10x more common than PET/CT in India and globally. By achieving comparable performance with CT alone, we enable advanced radiotherapy planning in community hospitals and resource-limited settings where PET/CT is unavailable.
                </p>

                <div class="stats-grid">
                    <div class="stat-box">
                        <div class="stat-value">167</div>
                        <div class="stat-label">Total Cases</div>
                    </div>
                    <div class="stat-box">
                        <div class="stat-value">0.65</div>
                        <div class="stat-label">Global Dice (Combined)</div>
                    </div>
                    <div class="stat-box">
                        <div class="stat-value">0.71</div>
                        <div class="stat-label">Median Dice</div>
                    </div>
                    <div class="stat-box">
                        <div class="stat-value">23.6mm</div>
                        <div class="stat-label">HD95 Boundary</div>
                    </div>
                </div>

                <h4 class="contributions-title">üéØ Key Achievements</h4>
                <ul class="contributions-list">
                    <li><strong>Multi-institutional dataset curation:</strong> Assembled and harmonized 167 cases from two institutions (137 MAASTRO public + 30 CMC private), implementing comprehensive de-identification and quality control protocols</li>
                    <li><strong>Performance on public HN1 dataset:</strong> Achieved Global Dice of <span class="metric">0.63</span>, Median Dice of <span class="metric">0.60</span>, demonstrating robust baseline performance on publicly available data</li>
                    <li><strong>Impact of private data integration:</strong> Adding 30 CMC cases (18% of training data) improved Global Dice to <span class="metric">0.65 (+3.99%)</span> and Median Dice to <span class="metric">0.71 (+18.56%)</span>, demonstrating value of institutional data diversity</li>
                    <li><strong>Fold-wise analysis insights:</strong> Identified that Fold 1 benefited most from additional data (Global Dice: 0.68, IoU: 0.52), while performance varied by fold, revealing sensitivity to case distribution and data heterogeneity</li>
                    <li><strong>Precision-sensitivity trade-offs:</strong> Achieved high precision (0.79-0.81) with moderate sensitivity (0.52-0.59), indicating conservative segmentation strategy that minimizes false positives‚Äîcritical for clinical safety</li>
                </ul>

                <h4 class="contributions-title">üî¨ Technical Methodology</h4>
                <ul class="contributions-list">
                    <li><strong>Architecture:</strong> Implemented 3D nnU-Net with self-configuring preprocessing pipeline, automatically optimizing patch size, batch size, and network topology for head and neck CT data</li>
                    <li><strong>Training strategy:</strong> Three-fold cross-validation with careful patient-level splitting to prevent data leakage, trained on NVIDIA L40 GPU (48GB) using PyTorch and CUDA 12.6</li>
                    <li><strong>Evaluation metrics:</strong> Comprehensive assessment using Global Dice, Median Dice, IoU, Precision, Sensitivity, Specificity, and HD95 for boundary accuracy</li>
                    <li><strong>Data harmonization:</strong> Standardized imaging parameters, voxel spacing, and intensity normalization across public MAASTRO and private CMC datasets</li>
                    <li><strong>Clinical validation:</strong> Qualitative evaluation by radiation oncologists confirmed strong spatial agreement with expert annotations, with minor under-segmentation in diffuse tumor boundaries</li>
                </ul>

                <h4 class="contributions-title">üìä Key Findings & Challenges</h4>
                <ul class="contributions-list">
                    <li><strong>Boundary accuracy challenge:</strong> HD95 increased from 16mm to 24mm with additional data, indicating reduced boundary precision‚Äîlikely due to inter-institutional annotation style differences</li>
                    <li><strong>Center-specific variability:</strong> Fold-dependent performance suggests sensitivity to institutional imaging protocols and annotation practices, highlighting need for domain adaptation techniques</li>
                    <li><strong>Conservative segmentation strategy:</strong> High specificity (>0.9998) but lower sensitivity indicates model tends to under-segment rather than over-segment, which is clinically safer but may miss small tumor extensions</li>
                </ul>

                <h4 class="contributions-title">üöÄ Future Directions</h4>
                <ul class="contributions-list">
                    <li>Integrate domain adaptation to reduce center-specific variability</li>
                    <li>Leverage few-shot learning to address limited annotation challenges</li>
                    <li>Expand private dataset to 100+ cases for more balanced fold representation</li>
                    <li>Explore foundation models (MedSAM) and hybrid nnU-Net approaches</li>
                    <li>Systematic benchmarking of CT-only vs. PET/CT fusion methods</li>
                </ul>

                <div class="tech-section">
                    <div class="tech-label">Technologies & Tools</div>
                    <div class="tech-tags">
                        <span class="tech-tag">Python 3.9+</span>
                        <span class="tech-tag">nnU-Net V2</span>
                        <span class="tech-tag">PyTorch</span>
                        <span class="tech-tag">MONAI</span>
                        <span class="tech-tag">3D CNN</span>
                        <span class="tech-tag">NVIDIA L40 GPU</span>
                        <span class="tech-tag">CUDA 12.6</span>
                        <span class="tech-tag">DICOM Processing</span>
                    </div>
                </div>

                <div class="project-links">
                    <a href="#" class="project-link">
                        üìÑ Paper Under Review (JIIM)
                    </a>
                    <a href="#" class="project-link">
                        üèÜ 3rd Prize - Winter Symposium 2025
                    </a>
                </div>
            </div>

            <!-- Project 5: Large-Scale Data Curation -->
            <div class="project-card">
                <div class="project-header">
                    <div>
                        <h3 class="project-title">Large-Scale Imaging Data Curation for Prospective Radiomics Trials</h3>
                        <p class="project-org">DBT/Wellcome Trust India Alliance Funded | ‚Çπ1.35 Crore Grant | PI: Dr. Hannah Mary Thomas T</p>
                    </div>
                    <span class="project-period">2020 - 2025</span>
                </div>

                <p class="project-description">
                    <strong>Project Vision:</strong> This prospective study aims to answer a fundamental question in precision oncology: <em>Can pre-treatment radiomics signatures accurately identify advanced head and neck cancer patients at higher risk of recurrence and poor survival outcomes?</em> By developing robust image analysis pipelines and predictive models, we seek to enable personalized treatment strategies and optimize limited radiotherapy resources.
                </p>

                <p class="project-description">
                    <strong>Scientific Foundation:</strong> Cancer radiomics converts routine radiological images into quantifiable tumor phenotypes. Unlike tissue biopsies that sample only small regions, radiomics captures information from the entire tumor non-invasively from standard clinical scans, providing comprehensive tumor characterization without additional radiation exposure or procedures for patients.
                </p>

                <p class="project-description">
                    <strong>Clinical Significance:</strong> Accurately estimating individual patient risk is crucial for understanding tumor biology, stratifying patients based on risk profiles, tailoring personalized treatment strategies, and optimizing use of limited radiotherapy resources in resource-constrained healthcare settings.
                </p>

                <div class="stats-grid">
                    <div class="stat-box">
                        <div class="stat-value">~1700</div>
                        <div class="stat-label">Patients Enrolled</div>
                    </div>
                    <div class="stat-box">
                        <div class="stat-value">5 Years</div>
                        <div class="stat-label">Prospective Study</div>
                    </div>
                    <div class="stat-box">
                        <div class="stat-value">‚Çπ1.35Cr</div>
                        <div class="stat-label">Funding</div>
                    </div>
                    <div class="stat-box">
                        <div class="stat-value">PET+CT</div>
                        <div class="stat-label">Multimodal</div>
                    </div>
                </div>

                <h4 class="contributions-title">üéØ My Contributions (2024-2025)</h4>
                <ul class="contributions-list">
                    <li><strong>End-to-end radiomics pipeline development:</strong> Designed and implemented complete workflow from DICOM retrieval (Orthanc) ‚Üí GTV-P segmentation (Citric) ‚Üí PyRadiomics feature extraction, enabling reproducible model training across ~1700 patient cohort</li>
                    <li><strong>Quality assurance at scale:</strong> Established systematic protocols for imaging and clinical data validation, ensuring data integrity across 5-year prospective collection period</li>
                    <li><strong>AWS cloud infrastructure:</strong> Implemented automated S3 pipelines for secure backup and disaster recovery of imaging data, ensuring long-term data preservation and accessibility</li>
                    <li><strong>Data annotation coordination:</strong> Helped coordinate workflows between radiation oncologists, medical physicists, and data scientists for consistent GTV-P delineation across large patient cohort</li>
                    <li><strong>Infrastructure planning:</strong> Drafted NVIDIA Academic Grant Proposal justifying need for high-performance GPU infrastructure for in-house deployment of large-scale deep learning models in clinical environment</li>
                </ul>

                <h4 class="contributions-title">üìä Project Aims & Progress</h4>
                <ul class="contributions-list">
                    <li><strong>Aim 1 - Robust Segmentation Pipeline:</strong> Developed automated tumor segmentation workflow for PET and CT imaging, with collaborative validation through NIT Surathkal partnership</li>
                    <li><strong>Aim 2 - Predictive Modeling:</strong> Built machine learning models using LASSO, SelectKBest, PSO, and WOA feature selection across multiple classifiers (Logistic Regression, SVM, Random Forest, etc.)</li>
                    <li><strong>Aim 3 - Imaging Archive:</strong> Successfully collected data from 1550+ HNC patients prospectively, forming valuable resource for validation and future multi-institutional studies</li>
                </ul>

                <h4 class="contributions-title">üî¨ Technical Infrastructure</h4>
                <ul class="contributions-list">
                    <li><strong>DICOM management:</strong> Orthanc-based PACS for centralized storage, retrieval, and anonymization of imaging data with RESTful API integration</li>
                    <li><strong>Segmentation workflow:</strong> Citric platform for collaborative GTV-P delineation with version control and quality metrics tracking</li>
                    <li><strong>Feature extraction:</strong> PyRadiomics-based automated extraction of first-order statistics, shape features, and texture features (GLCM, GLRLM, GLSZM)</li>
                    <li><strong>Cloud infrastructure:</strong> AWS S3 with automated backup schedules, encryption at rest, and multi-region replication for disaster recovery</li>
                    <li><strong>Data governance:</strong> Implemented FAIR principles, institutional IRB compliance, and patient consent tracking systems</li>
                </ul>

                <h4 class="contributions-title">üèÜ Academic Contributions</h4>
                <ul class="contributions-list">
                    <li><strong>Oral Presentation:</strong> "Can CT Radiomics Predict Recurrence in Head and Neck Cancer? Early Results from a Prospective Imaging Trial" at 14th Annual Research Day, CMC Vellore (Oct 2024)</li>
                    <li><strong>Conference Participation:</strong> 2nd Annual Winter Symposium on Health Data and AI - Organizing Team Member (March 2025)</li>
                    <li><strong>CME Attendance:</strong> Revolution and Precision in Radiation Oncology, CMC Vellore (March 2025)</li>
                </ul>

                <div class="tech-section">
                    <div class="tech-label">Technologies & Tools</div>
                    <div class="tech-tags">
                        <span class="tech-tag">Python</span>
                        <span class="tech-tag">Orthanc PACS</span>
                        <span class="tech-tag">PyRadiomics</span>
                        <span class="tech-tag">AWS S3</span>
                        <span class="tech-tag">DICOM</span>
                        <span class="tech-tag">Docker</span>
                        <span class="tech-tag">Citric</span>
                        <span class="tech-tag">RESTful API</span>
                        <span class="tech-tag">ETL Pipeline</span>
                    </div>
                </div>
            </div>
        </section>

        <!-- STARlab Capital -->
        <section class="project-section">
            <div class="section-header">
                <span class="section-icon">üìä</span>
                <h2 class="section-title">Quantitative Finance</h2>
            </div>

            <div class="project-card">
                <div class="project-header">
                    <div>
                        <h3 class="project-title">Volatility-Based Trading Strategy Development</h3>
                        <p class="project-org">STARlab Capital, Lucknow</p>
                    </div>
                    <span class="project-period">Dec 2023 - Jun 2024</span>
                </div>

                <p class="project-description">
                    Designed, backtested, and deployed sophisticated volatility-based trading strategies using proprietary tools, demonstrating transferable skills in quantitative analysis and model optimization.
                </p>

                <div class="stats-grid">
                    <div class="stat-box">
                        <div class="stat-value">52.38%</div>
                        <div class="stat-label">ROI Improvement</div>
                    </div>
                </div>

                <h4 class="contributions-title">üéØ Key Contributions</h4>
                <ul class="contributions-list">
                    <li>Designed, backtested, and deployed volatility-based strategies (Nebula, ARUT, A2) using <strong>OptionNet Explorer, Mesosim, OptiTrade, OptiBot</strong> tools</li>
                    <li>Enhanced the ARUT strategy, increasing ROI by <span class="metric">52.38%</span> through scenario-driven optimization and real-time feedback</li>
                    <li>Refined internal platforms: improved trade logs, added dynamic filters, and led contributions to OptiTrade's open-source GitHub repository</li>
                </ul>

                <div class="tech-section">
                    <div class="tech-label">Technologies & Tools</div>
                    <div class="tech-tags">
                        <span class="tech-tag">Python</span>
                        <span class="tech-tag">OptionNet Explorer</span>
                        <span class="tech-tag">Backtesting</span>
                        <span class="tech-tag">Strategy Optimization</span>
                        <span class="tech-tag">Risk Management</span>
                    </div>
                </div>

                <div class="project-links">
                    <a href="https://github.com/charmtraders-apps/issue_tracker" target="_blank" class="project-link">
                        üîó OptiTrade GitHub
                    </a>
                </div>
            </div>
        </section>
    </div>

    <!-- Footer -->
    <footer class="footer">
        <div class="footer-content-wrapper">
            <div class="footer-left">
                <h3 class="footer-name">Hasan Shaikh</h3>
                <p class="footer-bio">
                    Clinical Data Scientist at QIRAIL, CMC Vellore. Working at the intersection of medical imaging, 
                    machine learning, and radiation oncology. Building intelligent systems that transform cancer care 
                    through CT-based radiomics and deep learning.
                </p>
                <div class="footer-quote">
                    <p class="quote-text">"The best way to predict the future is to invent it."</p>
                    <p class="quote-author">‚Äî Alan Kay</p>
                </div>
            </div>

            <div class="footer-right">
                <h3 class="connect-title">Connect</h3>
                <div class="social-links">
                    <a href="https://github.com/hash123shaikh" target="_blank" class="social-link">
                        <span class="social-icon">üîó</span>
                        <span>GitHub</span>
                    </a>
                    <a href="https://scholar.google.com/citations?user=9jjwZ8cAAAAJ" target="_blank" class="social-link">
                        <span class="social-icon">üéì</span>
                        <span>Google Scholar</span>
                    </a>
                    <a href="https://www.linkedin.com/in/hasann-shaikh/" target="_blank" class="social-link">
                        <span class="social-icon">üíº</span>
                        <span>LinkedIn</span>
                    </a>
                    <a href="mailto:hasanshaikh3198@gmail.com" class="social-link">
                        <span class="social-icon">üìß</span>
                        <span>Email</span>
                    </a>
                </div>
            </div>
        </div>

        <div class="footer-bottom">
            <p class="copyright">¬© 2025 Hasan Shaikh. All rights reserved.</p>
        </div>
    </footer>

    <script>
        // Particle animation
        const canvas = document.getElementById('particles');
        const ctx = canvas.getContext('2d');
        
        canvas.width = window.innerWidth;
        canvas.height = window.innerHeight;

        const particles = [];
        const particleCount = 80;

        class Particle {
            constructor() {
                this.x = Math.random() * canvas.width;
                this.y = Math.random() * canvas.height;
                this.vx = (Math.random() - 0.5) * 0.5;
                this.vy = (Math.random() - 0.5) * 0.5;
                this.size = Math.random() * 2 + 1;
            }

            update() {
                this.x += this.vx;
                this.y += this.vy;

                if (this.x < 0 || this.x > canvas.width) this.vx *= -1;
                if (this.y < 0 || this.y > canvas.height) this.vy *= -1;
            }

            draw() {
                ctx.fillStyle = 'rgba(0, 212, 255, 0.5)';
                ctx.beginPath();
                ctx.arc(this.x, this.y, this.size, 0, Math.PI * 2);
                ctx.fill();
            }
        }

        for (let i = 0; i < particleCount; i++) {
            particles.push(new Particle());
        }

        function animate() {
            ctx.clearRect(0, 0, canvas.width, canvas.height);

            particles.forEach(particle => {
                particle.update();
                particle.draw();
            });

            particles.forEach((p1, i) => {
                particles.slice(i + 1).forEach(p2 => {
                    const dx = p1.x - p2.x;
                    const dy = p1.y - p2.y;
                    const distance = Math.sqrt(dx * dx + dy * dy);

                    if (distance < 150) {
                        ctx.strokeStyle = `rgba(0, 212, 255, ${0.2 * (1 - distance / 150)})`;
                        ctx.lineWidth = 1;
                        ctx.beginPath();
                        ctx.moveTo(p1.x, p1.y);
                        ctx.lineTo(p2.x, p2.y);
                        ctx.stroke();
                    }
                });
            });

            requestAnimationFrame(animate);
        }

        animate();

        window.addEventListener('resize', () => {
            canvas.width = window.innerWidth;
            canvas.height = window.innerHeight;
        });
    </script>
</body>
</html>
