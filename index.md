---
layout: single
title: ""
permalink: /
author_profile: true
classes: wide
---

<style>
.important-text { color: #007bff; font-weight: 600; }
.collaboration-text { color: #dc3545; font-weight: 600; }
.highlight-box { 
  background: rgba(248, 249, 250, 0.95); 
  border-left: 4px solid #dc3545; 
  padding: 1rem; 
  margin: 1rem 0; 
  border-radius: 4px; 
}

/* Creative color highlighting */
.vision-text { 
  color: #28a745; 
  font-weight: 600; 
}
.tech-highlight { 
  color: #6f42c1; 
  font-weight: 600; 
}
.metric-highlight { 
  color: #fd7e14; 
  font-weight: 700; 
}
.location-text { 
  color: #20c997; 
  font-weight: 600; 
}
.question-highlight {
  color: #e83e8c;
  font-weight: 600;
  font-style: italic;
}

/* Vanta background - behind everything */
#vanta-bg {
  position: fixed;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  z-index: -1 !important;
}

/* Sidebar - highest priority */
.sidebar {
  position: relative;
  z-index: 100 !important;
  background: rgba(255, 255, 255, 0.95) !important;
  padding: 1rem !important;
  border-radius: 8px !important;
}

/* Main content area */
.page__inner-wrap {
  position: relative;
  z-index: 50 !important;
  background: rgba(255, 255, 255, 0.92) !important;
  padding: 2rem !important;
  border-radius: 8px !important;
}

/* Navigation and footer */
.masthead,
.page__footer {
  position: relative;
  z-index: 75 !important;
}

.page__content {
  font-size: 0.9rem;
  line-height: 1.5;
}
.page__content h2 {
  font-size: 1.4rem;
  color: #2c3e50;
}
.page__content h3 {
  font-size: 1.2rem;
}
</style>

<div id="vanta-bg"></div>

I'm **Hasan Shaikh**, a <span class="important-text">Clinical Data Scientist</span> at the <span class="important-text">Quantitative Imaging Research and Artificial Intelligence Lab (QIRAIL)</span>, <span class="important-text">Christian Medical College (CMC) Vellore</span>, working at the intersection of <span class="tech-highlight">medical imaging</span>, <span class="tech-highlight">machine learning</span>, and <span class="vision-text">radiation oncology</span>.

My research explores how <span class="vision-text">AI can transform cancer care</span> in diverse clinical settings. I focus on developing <span class="tech-highlight">CT-based radiomics</span> and <span class="tech-highlight">deep learning approaches</span> that deliver precision oncology across different healthcare environments — from tertiary care centers to community hospitals. The driving question: <span class="question-highlight">how do we build intelligent systems that scale effectively and serve patients wherever they are?</span>

---

## The Journey

From <span class="location-text">Agra</span> to <span class="location-text">Aligarh</span> to <span class="location-text">Vellore</span>, my path has been guided by a singular focus: building AI systems that address real clinical needs. During my master's at Aligarh Muslim University (AMU), India <span class="metric-highlight">(CGPA 8.80/10)</span>, I worked on <span class="tech-highlight">multimodal survival prediction models</span>, discovering that the most meaningful research emerges from understanding both technical possibilities and clinical realities.

Before joining QIRAIL, I spent time in quantitative finance at STARlab Capital, designing volatility-based trading strategies. That experience—backtesting models under real-world uncertainty, optimizing risk-reward ratios, and improving ROI by <span class="metric-highlight">52%</span>—taught me principles that translate directly to clinical ML: the importance of <span class="vision-text">robust validation</span>, the danger of overfitting to pristine datasets, and the discipline required to build systems that work when it matters.

At CMC Vellore, I'm part of a team advancing cancer research through <span class="vision-text">methodological rigor</span>, <span class="vision-text">creative problem-solving</span>, and innovative approaches to resource optimization. We're demonstrating what's possible when technical excellence meets clinical insight.

---

## What I Build

I develop <span class="tech-highlight">machine learning models</span> for cancer outcome prediction and <span class="tech-highlight">automated tumor segmentation</span>, with emphasis on clinical deployability and real-world performance. My work spans <span class="important-text">radiomics-based prognostication</span>, <span class="important-text">3D deep learning for automated segmentation</span>, and large-scale imaging infrastructure that enables reproducible multi-institutional research.

The technical approach prioritizes <span class="vision-text">reproducibility</span> and <span class="vision-text">translational impact</span>: FAIR-compliant data pipelines, rigorous multi-institutional validation, and deployment-ready architectures. I work with <span class="tech-highlight">PyRadiomics</span>, <span class="tech-highlight">PyTorch</span>, <span class="tech-highlight">nnU-Net</span>, and cloud infrastructure (<span class="tech-highlight">AWS S3</span>) to build end-to-end systems that transform DICOM images into clinical insights.

The goal extends beyond model development — it's about creating tools that <span class="vision-text">physicians trust</span> and <span class="vision-text">patients benefit from</span>, regardless of their healthcare setting.

---

## The Vision

Healthcare AI holds <span class="vision-text">tremendous potential</span>. In India alone, over <span class="metric-highlight">a million people</span> receive cancer diagnoses annually. Many would benefit from advanced imaging analysis, personalized treatment planning, and evidence-based risk stratification—capabilities that AI can help deliver.

My work aims to demonstrate that <span class="important-text">CT-based approaches can achieve clinically meaningful performance</span>, that <span class="vision-text">open-source tools and FAIR data practices</span> can democratize research capabilities, and that <span class="vision-text">precision oncology can scale</span> through intelligent system design and methodological innovation. The opportunity lies in <span class="question-highlight">building AI that works for everyone</span>, not just those in the most resource-rich settings.

---

## Looking Forward

I'm actively seeking <span class="collaboration-text">PhD positions in Medical AI, Computer Vision, or Biomedical Engineering</span> for <span class="metric-highlight">Fall 2025/Spring 2026</span>. I'm interested in programs that value <span class="vision-text">translational research</span>, <span class="vision-text">methodological rigor</span>, and <span class="vision-text">real-world clinical impact</span>.

I welcome collaborations on <span class="important-text">multi-institutional validation studies</span>, <span class="important-text">clinical deployment of radiomics models</span>, and any work advancing healthcare AI accessibility. If your research intersects with <span class="tech-highlight">quantitative imaging</span>, <span class="tech-highlight">oncology outcomes</span>, or <span class="tech-highlight">scalable clinical AI systems</span>—let's connect.

[Research Projects](/portfolio/){: .btn .btn--primary} [Publications](/publications/){: .btn .btn--info} [Download CV](/files/CV_Hasan_Shaikh.pdf){: .btn .btn--success} [Contact Me](/contact/){: .btn .btn--warning}

---

<script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r134/three.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/vanta@latest/dist/vanta.birds.min.js"></script>
<script>
VANTA.BIRDS({
  el: "#vanta-bg",
  mouseControls: true,
  touchControls: true,
  gyroControls: false,
  minHeight: 200.00,
  minWidth: 200.00,
  scale: 1.00,
  scaleMobile: 1.00,
  backgroundColor: 0xfaefe9,
  color1: 0x306e91,
  color2: 0xafb4cf,
  colorMode: "lerp",
  birdSize: 0.80,
  wingSpan: 20.00,
  speedLimit: 3.00,
  separation: 45.00,
  alignment: 25.00,
  cohesion: 82.00,
  quantity: 2.00
})
</script>
